{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# _Computational Linguistics_ Code"
      ],
      "metadata": {
        "id": "Wc2acaTVrjsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yETQqMle5cK",
        "outputId": "49c6bd93-27c5-4004-b63b-a069ffb44ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the excel data\n",
        "import pandas as pd\n",
        "import matplotlib.colors as mc # For the legend\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9gjii6NyFtIz"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IU-token Class Definition"
      ],
      "metadata": {
        "id": "8Xe7E3Rdr1hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CSTokenMetricsComparisons:\n",
        "  def __init__(self, data, n_languages=2, IU_tag_col_name=\"Clean Lang Tag\", word_tag_col_name = \"Words Lang Tag\", text_col_name=\"IU no punctuation\"):\n",
        "    self.df = data\n",
        "    self.IU_tag_col_name = IU_tag_col_name\n",
        "    self.word_tag_col_name = word_tag_col_name\n",
        "    self.text_col_name = text_col_name\n",
        "    self.n_languages = n_languages\n",
        "    self.IU_lang_visualizations = []\n",
        "    \"\"\"\n",
        "    Dictionary storing all the ingo we will eventually populate. Entry examples include:\n",
        "    - total_rows      : how many IUs are there in the transcript? (int)\n",
        "    - IU_lang_rows    : language tags per IU after filtering non- S/E/L (list of strs)\n",
        "    - L_count         : how many lone items are present? (list of ints, counting Ls per IU)\n",
        "    - within-switch   : # of within IU CS (diff. based on the token) (int)\n",
        "    - across-switch   : # of of across IU CS (int)\n",
        "    - prosodic-switch : counting CS based on language and IU sentence (dict of SE/ES counts)\n",
        "    \"\"\"\n",
        "    self.data_dict = {\n",
        "        \"IU\"  : {\n",
        "            \"multi\": {},\n",
        "            \"both\" : {}\n",
        "        },\n",
        "        \"word\": {\n",
        "            \"multi\": {},\n",
        "            \"both\" : {}\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  This function should get called first, to populate the data_dict structure.\n",
        "  \"\"\"\n",
        "  def process_raw_info(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    prev_letter = \"\"\n",
        "    raw_counts = {\n",
        "        \"total_valid_rows\": 0,    # rows counted after filtering for desired language tags\n",
        "        \"total_rows\"      : 0,\n",
        "        \"lang_tag_counts\" : {\n",
        "                             \"S\": 0,\n",
        "                             \"E\": 0,\n",
        "                            },\n",
        "        \"L_count\"         : [],   # how many IUs have Ls? (and how many?)\n",
        "        \"IU_lang_rows\"    : [],   # language tag measurements after filtering out non- S/E/L\n",
        "    }\n",
        "\n",
        "    # get appropriate data column\n",
        "    data_rows = None\n",
        "    if token_level == \"IU\":\n",
        "      data_rows = self.df[self.IU_tag_col_name].astype(str)\n",
        "    elif token_level == \"word\":\n",
        "      data_rows = self.df[self.word_tag_col_name].astype(str)\n",
        "    else:\n",
        "      raise Exception(\"Did not enter a valid token level. Please enter either 'IU' or 'word'.\")\n",
        "\n",
        "    # loop through every IU row in the transcript\n",
        "    for i in range(len(data_rows)):\n",
        "      # we want to filter out anything that isn't L or S or E (depending on our 'include_L' flag)\n",
        "      curr_row = data_rows[i]\n",
        "      curr_row = [x for x in curr_row if x in [\"L\", \"S\", \"E\"]]\n",
        "      if len(curr_row) > 0:\n",
        "        raw_counts[\"total_valid_rows\"] += 1\n",
        "\n",
        "      # count the Ls in the current IU row\n",
        "      if CS_type == \"both\":\n",
        "        L_count = curr_row.count(\"L\")\n",
        "        raw_counts[\"L_count\"].append(L_count)\n",
        "\n",
        "      # process every tag in the IU\n",
        "      curr_tags = []\n",
        "      for lang_idx, lang in enumerate(curr_row):\n",
        "\n",
        "        # this will only happen once for each for loop / IU row;\n",
        "        if (token_level == \"IU\" and lang_idx == 0) or token_level == \"word\":\n",
        "          # properly increment the lang tag counts (currently for the IU)\n",
        "          if lang == \"S\":\n",
        "            raw_counts[\"lang_tag_counts\"][\"S\"] += 1\n",
        "          elif lang == \"E\":\n",
        "            raw_counts[\"lang_tag_counts\"][\"E\"] += 1\n",
        "\n",
        "        # populate the filtered language tags properly; if L, switch it according to the second param!\n",
        "        if lang == \"L\":\n",
        "          if prev_letter == \"E\":\n",
        "            if CS_type == \"both\": # it counts as CS, so we will switch it\n",
        "              curr_tags.append(\"L\")\n",
        "            else:\n",
        "              curr_tags.append(\"E\")\n",
        "          elif prev_letter == \"S\":\n",
        "            if CS_type == \"both\":\n",
        "              curr_tags.append(\"L\")\n",
        "            else:\n",
        "              curr_tags.append(\"S\")\n",
        "        else:\n",
        "          curr_tags.append(lang)\n",
        "\n",
        "        prev_letter = lang\n",
        "\n",
        "      raw_counts[\"IU_lang_rows\"].append(curr_tags)\n",
        "\n",
        "    raw_counts[\"total_rows\"] = len(raw_counts[\"IU_lang_rows\"])\n",
        "\n",
        "    self.data_dict[token_level][CS_type] = raw_counts\n",
        "    return raw_counts\n",
        "\n",
        "  \"\"\"\n",
        "  NOTES:\n",
        "  - This function does count the Ls.\n",
        "  - Because of that, some IUs from the total_valid_rows number don't actually count (i.e.,\n",
        "      if an IU starts with an L, for example).\n",
        "  \"\"\"\n",
        "  def m_index(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    # add a check here that throws an error in case they haven't processed raw counts yet\n",
        "    if len(self.data_dict[token_level][CS_type]) == 0:\n",
        "      raise Exception(\"Data hasn't been processed! Please call process_raw_counts with the same parameters before calling this function.\")\n",
        "\n",
        "    lang_counts = self.data_dict[token_level][CS_type][\"lang_tag_counts\"]\n",
        "    lang_counts = [lang_counts[\"E\"], lang_counts[\"S\"]]\n",
        "\n",
        "    # NOTE: Different number than self.data_dict[token_level][CS_type][\"total_valid_rows\"], which will also count a row as valid if it starts with an L (which we don't count here in our total).\n",
        "    total_rows = lang_counts[0] + lang_counts[1]\n",
        "\n",
        "    for i in range(len(lang_counts)):\n",
        "      lang_counts[i] /= total_rows\n",
        "      lang_counts[i] = lang_counts[i] ** 2\n",
        "\n",
        "    p_sum = lang_counts[0] + lang_counts[1]\n",
        "    self.M_index = (1 - p_sum) / ((self.n_languages - 1) * p_sum)\n",
        "\n",
        "    return self.M_index\n",
        "\n",
        "  def across_IU(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    if len(self.data_dict[token_level][CS_type]) == 0:\n",
        "      raise Exception(\"Data hasn't been processed! Please call process_raw_counts with the same parameters before calling this function.\")\n",
        "\n",
        "    tag_cols = self.data_dict[token_level][CS_type][\"IU_lang_rows\"]\n",
        "    prev = \"\"\n",
        "    total, switch_count = 0, 0\n",
        "    for row in tag_cols:\n",
        "      if len(row) > 0:\n",
        "        total += 1\n",
        "      for i, tag in enumerate(row):\n",
        "        if i == 0 and prev != \"\" and prev != tag and prev != \"L\":\n",
        "          switch_count += 1\n",
        "        prev = tag\n",
        "    self.data_dict[token_level][CS_type][\"across-switch\"] = switch_count\n",
        "\n",
        "    return switch_count, total\n",
        "\n",
        "  \"\"\"\n",
        "  Remember: this is a binary count that only counts once if a switch is present within the IU.\n",
        "  \"\"\"\n",
        "  def within_IU(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    if len(self.data_dict[token_level][CS_type]) == 0:\n",
        "      raise Exception(\"Data hasn't been processed! Please call process_raw_counts with the same parameters before calling this function.\")\n",
        "\n",
        "    tag_cols = self.data_dict[token_level][CS_type][\"IU_lang_rows\"]\n",
        "\n",
        "    total, switch_count = 0, 0\n",
        "    for row in tag_cols:\n",
        "      if len(row) > 0:\n",
        "        total += 1\n",
        "        # the below is to ensure we don't double count, since an L will already be considerd as an across IU switch\n",
        "        if row[0] == \"L\":\n",
        "          row = row[1:]\n",
        "        unique_tags = set(\"\".join(row))\n",
        "        if len(unique_tags) > 1:\n",
        "          switch_count += 1\n",
        "    self.data_dict[token_level][CS_type][\"within-switch\"] = switch_count\n",
        "\n",
        "    return switch_count, total\n",
        "\n",
        "  def i_index(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    if len(self.data_dict[token_level][CS_type]) == 0:\n",
        "      raise Exception(\"Data hasn't been processed! Please call process_raw_counts with the same parameters before calling this function.\")\n",
        "\n",
        "    if token_level == \"IU\":\n",
        "      return self.__iu_i_index__(CS_type, token_level)\n",
        "    elif token_level == \"word\":\n",
        "      return self.__word_i_index__(CS_type, token_level)\n",
        "    raise Exception(\"Invalid token level. Pleaseuse either 'IU' or 'word'.\")\n",
        "\n",
        "  \"\"\"\n",
        "  This function calculates the normal I-Index using word tokens by going through\n",
        "  the transcript in sequential order. We only print the result, and don't return.\n",
        "  \"\"\"\n",
        "  def __word_i_index__(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    tag_cols = self.data_dict[token_level][CS_type][\"IU_lang_rows\"]\n",
        "\n",
        "    prev = \"\"\n",
        "    total, switch_count = 0, 0\n",
        "    for row in tag_cols:\n",
        "      for tag in row:\n",
        "        total += 1\n",
        "        # remember, we aren't counting switching out of a lone tag.\n",
        "        if prev != \"\" and prev != tag and prev != \"L\":\n",
        "          switch_count += 1\n",
        "        prev = tag\n",
        "\n",
        "    i_index = switch_count / (total - 1)\n",
        "\n",
        "    self.data_dict[token_level][CS_type][\"CS-count\"] = switch_count\n",
        "    self.data_dict[token_level][CS_type][\"I-index\"] = i_index\n",
        "    return switch_count, i_index\n",
        "\n",
        "  def __iu_i_index__(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    # within IU only\n",
        "    within_count, within_total = self.within_IU(CS_type, token_level)\n",
        "    across_count, across_total = self.across_IU(CS_type, token_level)\n",
        "\n",
        "    numerator = across_count + within_count - (across_count * (within_count / within_total))\n",
        "    i_index = numerator / max(within_total, across_total)\n",
        "\n",
        "    self.data_dict[token_level][CS_type][\"CS-count\"] = numerator\n",
        "    self.data_dict[token_level][CS_type][\"I-Index\"] = i_index\n",
        "    return numerator, i_index\n",
        "\n",
        "  def count_CS_prosodic(self, CS_type=\"multi\", token_level=\"IU\"):\n",
        "    if len(self.data_dict[token_level][CS_type]) == 0:\n",
        "      raise Exception(\"Data hasn't been processed! Please call process_raw_counts with the same parameters before calling this function.\")\n",
        "\n",
        "    tag_cols = self.data_dict[token_level][CS_type][\"IU_lang_rows\"]\n",
        "    word_col = self.df[self.text_col_name].astype(str).tolist()\n",
        "\n",
        "    prev = \"\"\n",
        "    SE, ES, total = 0, 0, 0\n",
        "    for i, tags in enumerate(tag_cols):\n",
        "      for j, tag in enumerate(tags):\n",
        "        if prev != \"\" and prev != tag: # there's a switch!\n",
        "          # is it within the prosodic boundary?\n",
        "          # the first condition checks if we're the 1st tag in our row AND the\n",
        "          # previous character of the transcription line isn't the end of a prosodic\n",
        "          # sentence. the second condition is if we're not the first tag in the IU.\n",
        "\n",
        "          if (j == 0 and word_col[i - 1][-1] not in [\".\", \"?\"]) or j > 0:\n",
        "              total += 1\n",
        "              if prev == \"E\" and tag == \"S\":\n",
        "                ES += 1\n",
        "              elif prev == \"S\" and tag == \"E\":\n",
        "                SE += 1\n",
        "              elif tag == \"L\":\n",
        "                if prev == \"E\":\n",
        "                  ES += 1\n",
        "                elif prev == \"S\":\n",
        "                  SE += 1\n",
        "              elif prev == \"L\":\n",
        "                total -= 1\n",
        "        prev = tag\n",
        "    assert (total == SE + ES)\n",
        "\n",
        "    self.data_dict[token_level][CS_type]['prosodic-CS'] = {\n",
        "        \"SE\"    : SE,\n",
        "        \"ES\"    : ES,\n",
        "        \"total\" : total\n",
        "    }\n",
        "    return SE, ES\n",
        "\n",
        "  def visualize_transcript(self, CS_type=\"multi\", token_level=\"IU\", cmap_colors=[\"#0a437a\", \"#ADD8E6\"], filepath=\"\", save=False):\n",
        "    if len(self.data_dict[token_level][CS_type]) == 0:\n",
        "      raise Exception(\"Data hasn't been processed! Please call process_raw_counts with the same parameters before calling this function.\")\n",
        "\n",
        "    tag_cols = self.data_dict[token_level][CS_type][\"IU_lang_rows\"]\n",
        "    # tags_merged = [tag for tags in tag_cols for tag in tags if tag in [\"S\", \"E\"]]\n",
        "    # tags_merged = np.asarray(tags_merged)\n",
        "    # print(tags_merged)\n",
        "    # lang_distr = np.where(tags_merged == \"E\", 0, 1)\n",
        "\n",
        "    lang_distributions = []\n",
        "    for tags in tag_cols:\n",
        "      for tag in tags:\n",
        "        if tag == \"E\":\n",
        "          lang_distributions.append(0)\n",
        "        elif tag == \"S\":\n",
        "          lang_distributions.append(1)\n",
        "    # print(lang_distr)\n",
        "    lang_distributions = np.asarray(lang_distributions).reshape(1, len(list(lang_distributions)), order=\"F\")\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "    if len(cmap_colors) != self.n_languages:\n",
        "      raise Exception(f\"Number of colors for plot should match # of languages, i.e., {self.n_languages}.\")\n",
        "\n",
        "    cmap = matplotlib.colors.ListedColormap(cmap_colors)\n",
        "    ax.pcolormesh(lang_distributions, cmap=cmap)\n",
        "    ax.set_frame_on(False)\n",
        "    plt.yticks([])\n",
        "    ax.set_ylim(top=0.5)\n",
        "\n",
        "    if save:\n",
        "      plt.savefig(filepath)\n",
        "    return"
      ],
      "metadata": {
        "id": "tWr0vS5Pr6eO"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Transcript"
      ],
      "metadata": {
        "id": "ZUQhTk9AEvuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/Code-Switching-Work/updated-data/\"\n",
        "file = \"15LasCosasViejas_for Rebecca-WORDS-updated.csv\"\n",
        "df = pd.read_csv(filepath + file)"
      ],
      "metadata": {
        "id": "Qb8xcpCBEiPT"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = CSTokenMetricsComparisons(df)"
      ],
      "metadata": {
        "id": "JoAVnUnXExJO"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" IU METRICS: just have to fix the count_CS_prosodic \"\"\"\n",
        "\n",
        "# print the file we're working with\n",
        "print(f\"Processing IU token for file {file}...\\n\")\n",
        "\n",
        "# populate the S/E counts\n",
        "no_L_IU = metrics.process_raw_info(CS_type=\"multi\")\n",
        "L_IU    = metrics.process_raw_info(CS_type=\"both\")\n",
        "\n",
        "print(f\"Total number of IUs: {no_L_IU['total_rows']}\\n\")\n",
        "\n",
        "# print the S/E counts\n",
        "print(f\"# of IUs as S: {no_L_IU['lang_tag_counts']['S']} \\n#of IUs as E:{no_L_IU['lang_tag_counts']['E']}\\n\")\n",
        "\n",
        "# Calculate the M-Index\n",
        "m_index = metrics.m_index()\n",
        "print(f\"M-Index: {round(m_index, 2)}\\n\")\n",
        "\n",
        "# Calculate the I-Indeces\n",
        "CS_num_no_Ls, no_Ls_I_index = metrics.i_index()\n",
        "CS_num_Ls, Ls_I_index = metrics.i_index(CS_type=\"both\")\n",
        "\n",
        "print(f\"Estimated numerator for multi-word CS (IU level): {round(CS_num_no_Ls, 2)} \\nIU-Index: {round(no_Ls_I_index, 2)}\\n\")\n",
        "print(f\"Estimated numerator when including Ls as CS (IU level): {round(CS_num_Ls, 2)} \\nIU-Index: {round(Ls_I_index, 2)}\\n\")\n",
        "\n",
        "# get the prosodic CS\n",
        "SE, ES = metrics.count_CS_prosodic(CS_type=\"both\")\n",
        "print(f\"Prosodic CS: \\nSE: {SE} \\nES: {ES}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkItMpucE0EP",
        "outputId": "93fc4889-bfb4-455a-a897-397e807b43ec"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 15LasCosasViejas_for Rebecca-WORDS-updated.csv...\n",
            "\n",
            "Total number of IUs: 2815\n",
            "\n",
            "# of IUs as S: 538 \n",
            "#of IUs as E:1723\n",
            "\n",
            "M-Index: 0.57\n",
            "\n",
            "Estimated numerator for multi-word CS (IU level): 347.11 \n",
            "IU-Index: 0.15\n",
            "\n",
            "Estimated numerator when including Ls as CS (IU level): 378.29 \n",
            "IU-Index: 0.17\n",
            "\n",
            "Prosodic CS: \n",
            "SE: 165 \n",
            "ES: 193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" WORD METRICS: check \"\"\"\n",
        "\n",
        "print(f\"Processing word token for file {file}...\\n\")\n",
        "\n",
        "# populate the S/E counts\n",
        "no_L_raw_counts = metrics.process_raw_info(token_level=\"word\", CS_type=\"multi\")\n",
        "L_raw_counts    = metrics.process_raw_info(token_level=\"word\",CS_type=\"both\")\n",
        "\n",
        "print(f\"Total number of words: {no_L_raw_counts['total_rows']}\\n\")\n",
        "\n",
        "# print the S/E counts\n",
        "print(f\"# of words as S: {no_L_raw_counts['lang_tag_counts']['S']}\")\n",
        "print(f\"# of words as E: {no_L_raw_counts['lang_tag_counts']['E']}\\n\")\n",
        "\n",
        "# Calculate the I-Indeces\n",
        "CS_num_no_Ls, no_Ls_I_index = metrics.i_index(token_level=\"word\")\n",
        "CS_num_Ls, Ls_I_index = metrics.i_index(token_level=\"word\", CS_type=\"both\")\n",
        "\n",
        "print(f\"# of multi-word CS (word level): {CS_num_no_Ls} \\nI-Index including Ls as CS (word level): {no_Ls_I_index}\\n\")\n",
        "print(f\"# of CS wheh including Ls as CS (word level): {CS_num_Ls} \\nI-Index when including Ls as CS (word level): {Ls_I_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTLZ5ZfHocVi",
        "outputId": "1bcf79a7-256f-43d2-e8a1-9a606fa64041"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing word token for file 15LasCosasViejas_for Rebecca-WORDS-updated.csv...\n",
            "\n",
            "Total number of words: 2815\n",
            "\n",
            "# of words as S: 1563\n",
            "# of words as E: 6678\n",
            "\n",
            "# of multi-word CS (word level): 350 \n",
            "I-Index including Ls as CS (word level): 0.04223992276128409\n",
            "\n",
            "# of CS wheh including Ls as CS (word level): 385 \n",
            "I-Index when including Ls as CS (word level): 0.046463915037412505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the word-based transcripts\n",
        "metrics.visualize_transcript(token_level=\"word\", CS_type=\"multi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "1uWAz7yZq12L",
        "outputId": "8c655465-c118-48ea-95e8-f96344d3c2dd"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}